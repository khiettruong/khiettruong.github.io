<!DOCTYPE HTML>
<!--
	Dopetrope by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Khiet Truong - Research</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />

	</head>
	<body class="no-sidebar is-preload">
		<div id="page-wrapper">

			<!-- Header -->
				<section id="header">

					<!-- Logo -->
						<h1><a href="index.html">Personal Page of Khiet Truong</a></h1>

					<!-- Nav -->
						<nav id="nav">
							<ul>
								<li><a href="index.html">Home</a></li>
								<li><a href="blog.html">Blog</a></li>
								<li>
									<a href="research.html">Research</a>
									<ul>
										<li><a href="research.html#projects">Projects</a></li>
										<li><a href="research.html#PhDSupervision">PhD supervision</a></li>
										<li><a href="research.html#AcademicService">Academic service</a></li>
									</ul>
								</li>
								<li>
									<a href="teaching.html">Teaching</a>
									<ul>
										<li><a href="teaching.html#courses">Courses</a></li>
										<li><a href="teaching.html#studentassignments">Student assignments</a></li>
									</ul>
								</li>
								<li><a href="publications.html">Publications</a>
								</li>
								<li><a href="photos.html">Photos</a></li>
								<li><a href="#Contact">Contact</a></li>
							</ul>
						</nav>

				</section>

			<!-- Main -->
				<section id="main">
					<div class="container">

						<!-- Content -->
							
								<!--<a href="#" class="image featured"><img src="images/pic01.jpg" alt="" /></a>-->
								<header>
									<h2>Research</h2>
								
								</header>
								<article class="box post">
									<h3 id="Projects">Projects</h3>
									<p><h4><a href="https://www.utwente.nl/nieuws/!/2019/1/191048/project-kinderen-in-gesprek-met-media-van-start">Responsible child-robot-media interaction (SIDN fonds, in collaboration with the Netherlands Institute for Sound and Vision) | 2019 - current</a></h4>
									When we search online for information, it is becoming more and more common - especially for the younger generation - to do this via 'social agents'. Think of Amazon Alexa, Google Assistant or even robots. However, we still know little about how children experience this. Children are quick to see social agents and robots as their equals and are quick to trust them. This project investigates how we can shape child-robot interaction in a responsible way in this information-seeking environment: this interaction not only focusses on informing in a way that children understand and like, but also pays attention to transparency (where does information come from?), privacy (what personal data are used?), and awareness about the use of AI.	
									</p>
									<p>
									<h4><a href="https://www.esciencecenter.nl/project/emotion-recognition-in-dementia">Science Center project on Advancing technology for multimodal analysis of emotion expression in everyday life | 2017 - current</a></h4>
									Emotional expression plays a crucial role in everyday functioning. It is a continuous process involving many features of behavioral, facial, vocal, and verbal modalities. Given this complexity, few psychological studies have addressed emotion recognition in an everyday context. Recent technological innovations in affective computing could result in a scientific breakthrough as they open up new possibilities for the ecological assessment of emotions. However, existing technologies still pose major challenges in the field of Big Data Analytics.
									</p>
									<p>
									<h4>4TU NIRICT project on Empathic Lighting | 2016 - 2017</h4>
									In this project, we collaborate on research at the intersections of technology and humans, in particular, combining insights from computational intelligence, user modeling, personalization and human-computer interaction for lighting installations that can adapt to and influence people’s affective states. We aim to develop affect-adaptive lighting interfaces to be deployed in independent living for seniors. Seniors often experience negative affective states, such as gloominess due to the distance from their families or anxiety when disoriented (e.g. due to dementia).
									</p>
									<p>
									<h4>4TU Humans & Technology Smart Social Systems and Spaces for Living Well (S4) | 2015 - 2022 </h4>
									The 4TU research centre Humans & Technology brings together the social sciences, humanities, and technical sciences. Its goal is excellent research on innovative forms of human-technology interaction for smart social systems and spaces. The research program "Smart Social Systems and Spaces for Living Well" (S4) aims to combine knowledge available from different disciplines, such as computer science, psychology, and industrial design.
									</p>
									<p>
									<h4><a href="http://www.squirrel-project.eu">EU-FP7 SQUIRREL (Clearing Clutter Bit by Bit) | 2014 - 2018</a></h4>
									Development of a robot for children (4-10 years old) that cannot only perform complex navigation, detection, and manipulation tasks in a cluttered environment, but is also affectively and socially intelligent, engaging and fun in a collaborative task. Detection of children’s affective and social states (e.g., engagement, dominant behavior) in a multiparty robot-children scenario (1 robot and more than 1 child) through (non-verbal) speech analysis.
									</p>
									<p>
									<h4><a href="http://teresaproject.eu">EU-FP7 TERESA (Telepresence Reinforcement-learning Social Agent) | 2014 - 2017</a></h4>
									Development of a socially-intelligent telepresence robot, e.g., semi-autonomously navigating among groups, adaptation to quality of the mediated human-human interaction (elderly people). Detecting and monitoring the quality (e.g., how well is the conversation going, are the interactants in sync, are they disagreeing, do they like each other) of the mediated human-human interaction through (non-verbal) speech analysis.
									</p>
									<p>
									<h4><a href="http://www.commit-nl.nl/projects/sensei-sensor-based-engagement-for-improved-health">COMMIT P3 (SENSEI) | 2013 - 2017</a></h4>
									Integration of technology to sense, analyse, interpret and motivate people who take part in sports and exercises (running) towards a better wellbeing. Detection of the runner’s physical and mental state through speech analysis.
									</p>
									<p>
									<h4>CroMe (Croatian Memories) | 2012 - 2013</h4>
									Gathering and documenting testimonies on war-related experiences in Croatia’s past, and making these audiovisual testimonies publicly available and searchable through technology. Analysis of verbal and non-verbal behavior of interviewees, for example, by comparing between word usage and prosodic speech parameters, and analysis of sighs in emotionally-colored dialogs.
									</p>
									<p>
									<h4><a href="http://www.semaine-project.eu">EU-FP7 SEMAINE (The Sensitive Agent project) | 2009 - 2013</a>
									</h4>
									Development of a Sensitive Artificial Listener, a multimodal dialogue system that can sustain an interaction with a user for some time and that react appropriately to the user’s non-verbal behavior. Analysis of interruptive agents, analysis of generation, detection, and timing of backchannels (listener responses).
									</p>
									<p>
									<h4>EU-FP7 SSPNet (Social Signal Processing Network) | 2009 - 2013</h4>
									Automatic (multimodal) analysis and detection of social signals, manifested through non-verbal cues, in interaction. Analysis of non-verbal vocalisations such as laughter and sighs in interaction, interruptions, synchrony/mimicry, listener responses in interaction.
									</p>
									<p>
									<h4>BSIK MultimediaN N2 (Multimodal Interaction) | 2005 - 2009</h4>
									Realizing an excellent user experience during a human-machine interaction by attuning the interaction to the user’s intentions and emotions. Automatic emotion recognition in speech, automatic detection of laughter, multimodal sentiment analysis.
									</p>


								
								
								</article>
								<article class="box post">
									<h3 id="PhDSupervision">PhD Supervision</h3>
									<p><h4>PhD students supervising/supervised</h4>
										<ul><li>Ella Velner, PhD student Child-Robot-Media-Interaction  (Oct 2019 - ...)</li>
											<li>Michel Jansen, PhD student 4TU Humans and Technology (Oct 2017 - ...)</li>
											<li>Deniece Nazareth, PhD student eScience project Emotion recognition in dementia (Maay 2017 - ...)</li>
											<li>Jaebok Kim, PhD student EU FP7 SQUIRREL (July 2014 - July 2018)</li>
											<li>Roelof de Vries, PhD student COMMIT P3 Sensor-based engagement for improved health (May 2013 - Nov 2018)</li>
											<li>Cristina Zaga, PhD student EU FP7 SQUIRREL (Oct 2014 - March 2021)</li>
										</ul>
									<h4>PhD dissertation committee</h4>
									<ul>
										<li>Wei Xue (2023). Measuring the intelligibility of pathological speech through subjective and objective procedures. (21 March 2023, Radboud University)</li>
										<li>Phoebe Mui (2019). The many faces of smiling: Social and cultural factors in the display and perception of smiles. (18 Dec 2019, Tilburg University)</li>
										<li>Juliane Schmidt Kirsch (2018). Listening for the WHAT and the HOW: Older adults’ processing of semantic and affective information in speech. (5 July 2018, Radboud University Nijmegen)</li>
 										<li>Selma Yilmazyildiz (2017). Semantic Free Affective Speech Framework For Social Human-Robot Interaction. (13 Sep 2017, Vrije Universiteit Brussel)</li>
									</ul>
									</p>
									
									
								
							</article>
								<article class="box post">
									<h3 id="AcademicService">Academic service</h3>
									<p>
									<h4>Member of Editorial Boards</h4>
									<ul>
										<li><strong>Member of Editorial Board Computer Speech and Language</strong> May 2021 - current</li>
										<li><strong>Associate Editor IEEE Transactions on Affective Computing</strong> Feb 2019 - current</li>
										<li><strong>ACM Transactions on Intelligent Interactive Systems (TiiS) (inaugural) Board of Distinguished Reviewers</strong> 2017-2018</li>
									</ul>
									</p>	
											
									<p>
									<h4>Conference organization / TPC / PC / reviewing (a selection)</h4>
									<ul>
									<li><strong>Interspeech</strong> General Co-Chair 2025 | Lead Area Chair 2023 | Lead Area Chair 2022 | Lead Area Chair 2021 | Area Chair 2017 | Area Chair 2015 | reviewer since 2011</li> 
									<li><strong>ACM International Conference on Multimodal Interaction (ICMI)</strong> Program Co-Chair 2024 | Publicity Chair 2023 | Senior PC, Social Media Chair 2021 | General Chair 2020 | Senior PC 2016 | reviewer 2017, 2015, 2014, 2013, 2012</li>
									<li><strong>IEEE International Conference on Affective Computing and Intelligent Interaction (ACII)</strong> Program Co-Chair 2022 | Senior PC 2021 | Senior PC, Tutorial Chair 2019 | Senior PC, Social Media Chair 2017 | reviewer 2015, 2013</li>
									<li><strong>ACM/IEEE International Conference on Human-Robot Interaction (HRI)</strong> PC 2023 | reviewer 2023, 2021, 2019, 2016, 2015</li>
									<li><strong>HRI Pioneers</strong> reviewer 2023, 2022, 2021, 2019, 2018</li>
									<li><strong>IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</strong> reviewer since 2013</li>
									<li><strong>Speech Prosody</strong> reviewer 2022, 2021, 2020, 2018, 2016, 2014</li>
									<li><strong>ACM International Conference on Intelligent Virtual Agents (IVA)</strong> Senior PC 2016 | Doctoral Consortium Chair 2015 | reviewer 2023, 2022, 2021, 2019, 2018</li>
									</ul>
									</p>					
							

					</div>
				</section>

			<!-- Footer -->
				<section id="footer">
					<div class="container">
						<div class="row">
							<div class="col-8 col-12-medium">
								<section>
									<header>
										<h2 id="Contact">Contact</h2>
									</header>
									<p>
										Dr. Khiet P. Truong, Associate professor</br>
										Human Media Interaction, University of Twente</br>
										Building Citadel, room H235</br>
										PO Box 217</br>
										7500 AE Enschede</br>
										The Netherlands</br>
										+31 (0)53 489 3683</br></br>

										k dot p dot truong at utwente dot nl
									</p>
									<ul class="social">
										<!--<li><a class="icon brands fa-facebook-f" href="#"><span class="label">Facebook</span></a></li>-->
										<li><a class="icon brands fa-twitter" href="https://www.twitter.com/khiettruong"><span class="label">Twitter</span></a></li>
										<!--<li><a class="icon brands fa-dribbble" href="#"><span class="label">Dribbble</span></a></li>-->
										<!--<li><a class="icon brands fa-tumblr" href="#"><span class="label">Tumblr</span></a></li>-->
										<li><a class="icon brands fa-linkedin-in" href="https://nl.linkedin.com/in/khiet-truong-34461014"><span class="label">LinkedIn</span></a></li>
										<li><a class="icon brands fa-google" href="https://scholar.google.com/citations?user=BP51q_oAAAAJ&hl=en"><span class="label">LinkedIn</span></a></li>
									</ul>
								</section>
							</div>
							
							<div class="col-12">

								<!-- Copyright -->
									<div id="copyright">
										<ul class="links">
											<li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
										</ul>
									</div>

							</div>
						</div>
					</div>
				</section>

		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>